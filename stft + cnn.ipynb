{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":7011868,"sourceType":"datasetVersion","datasetId":4031529}],"dockerImageVersionId":30587,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n#import os\n#for dirname, _, filenames in os.walk('/kaggle/input'):\n#    for filename in filenames:\n#       print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-11-30T19:21:12.147296Z","iopub.execute_input":"2023-11-30T19:21:12.147806Z","iopub.status.idle":"2023-11-30T19:21:12.617233Z","shell.execute_reply.started":"2023-11-30T19:21:12.147761Z","shell.execute_reply":"2023-11-30T19:21:12.616093Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Import Modules","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport os\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport librosa\nimport librosa.display\nfrom IPython.display import Audio\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"execution":{"iopub.status.busy":"2023-11-30T19:21:12.619383Z","iopub.execute_input":"2023-11-30T19:21:12.620018Z","iopub.status.idle":"2023-11-30T19:21:13.289411Z","shell.execute_reply.started":"2023-11-30T19:21:12.619972Z","shell.execute_reply":"2023-11-30T19:21:13.288236Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"paths=[]\nlabels=[]\nfor dirname, _, filenames in os.walk('/kaggle/input/tess-dataset'):\n   for filename in filenames:\n    paths.append(os.path.join(dirname,filename))\n    label = filename.split('_')[-1]\n    label = label.split('.')[0]\n    labels.append(label.lower())\nprint('Dataset is loaded')\n    ","metadata":{"execution":{"iopub.status.busy":"2023-11-30T19:21:13.290670Z","iopub.execute_input":"2023-11-30T19:21:13.290984Z","iopub.status.idle":"2023-11-30T19:21:14.364689Z","shell.execute_reply.started":"2023-11-30T19:21:13.290958Z","shell.execute_reply":"2023-11-30T19:21:14.363439Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"paths[:5]","metadata":{"execution":{"iopub.status.busy":"2023-11-30T19:21:14.367715Z","iopub.execute_input":"2023-11-30T19:21:14.368268Z","iopub.status.idle":"2023-11-30T19:21:14.377042Z","shell.execute_reply.started":"2023-11-30T19:21:14.368224Z","shell.execute_reply":"2023-11-30T19:21:14.375876Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"labels[:5]","metadata":{"execution":{"iopub.status.busy":"2023-11-30T19:21:14.378334Z","iopub.execute_input":"2023-11-30T19:21:14.378640Z","iopub.status.idle":"2023-11-30T19:21:14.389370Z","shell.execute_reply.started":"2023-11-30T19:21:14.378613Z","shell.execute_reply":"2023-11-30T19:21:14.388294Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"##Create a dataframe\ndf = pd.DataFrame()\ndf['speech']= paths\ndf['label']= labels\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2023-11-30T19:21:14.391046Z","iopub.execute_input":"2023-11-30T19:21:14.391715Z","iopub.status.idle":"2023-11-30T19:21:14.424888Z","shell.execute_reply.started":"2023-11-30T19:21:14.391685Z","shell.execute_reply":"2023-11-30T19:21:14.423620Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['label'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2023-11-30T19:21:14.426576Z","iopub.execute_input":"2023-11-30T19:21:14.426946Z","iopub.status.idle":"2023-11-30T19:21:14.442727Z","shell.execute_reply.started":"2023-11-30T19:21:14.426914Z","shell.execute_reply":"2023-11-30T19:21:14.441563Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# # Exploratory Data Analysis","metadata":{}},{"cell_type":"code","source":"sns.countplot(x='label', data=df)","metadata":{"execution":{"iopub.status.busy":"2023-11-30T19:21:14.444562Z","iopub.execute_input":"2023-11-30T19:21:14.444958Z","iopub.status.idle":"2023-11-30T19:21:14.859816Z","shell.execute_reply.started":"2023-11-30T19:21:14.444921Z","shell.execute_reply":"2023-11-30T19:21:14.858589Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def waveplot(data, sr, emotion):\n    plt.figure(figsize=(10, 4))\n    plt.title(emotion, size=20)\n    plt.plot(data)\n    plt.show()\n\ndef spectogram(data, sr, emotion):\n    x = librosa.stft(data)\n    xdb = librosa.amplitude_to_db(abs(x))\n    plt.figure(figsize=(11, 4))\n    plt.title(emotion, size=20)\n    librosa.display.specshow(xdb, sr=sr, x_axis='time', y_axis='hz')\n    plt.colorbar()","metadata":{"execution":{"iopub.status.busy":"2023-11-30T19:21:14.863507Z","iopub.execute_input":"2023-11-30T19:21:14.864483Z","iopub.status.idle":"2023-11-30T19:21:14.873854Z","shell.execute_reply.started":"2023-11-30T19:21:14.864410Z","shell.execute_reply":"2023-11-30T19:21:14.872872Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"emotion = 'fear'\npath = np.array(df['speech'][df['label'] == emotion])[0]\ndata, sampling_rate = librosa.load(path)\nwaveplot(data, sampling_rate, emotion)\nspectogram(data, sampling_rate, emotion)\nAudio(path)","metadata":{"execution":{"iopub.status.busy":"2023-11-30T19:21:14.879209Z","iopub.execute_input":"2023-11-30T19:21:14.879765Z","iopub.status.idle":"2023-11-30T19:21:28.168383Z","shell.execute_reply.started":"2023-11-30T19:21:14.879725Z","shell.execute_reply":"2023-11-30T19:21:28.167101Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"emotion = 'angry'\npath = np.array(df['speech'][df['label'] == emotion])[0]\ndata, sampling_rate = librosa.load(path)\nwaveplot(data, sampling_rate, emotion)\nspectogram(data, sampling_rate, emotion)\nAudio(path)","metadata":{"execution":{"iopub.status.busy":"2023-11-30T19:21:28.170337Z","iopub.execute_input":"2023-11-30T19:21:28.170995Z","iopub.status.idle":"2023-11-30T19:21:28.994365Z","shell.execute_reply.started":"2023-11-30T19:21:28.170956Z","shell.execute_reply":"2023-11-30T19:21:28.993232Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"emotion = 'disgust'\npath = np.array(df['speech'][df['label'] == emotion])[0]\ndata, sampling_rate = librosa.load(path)\nwaveplot(data, sampling_rate, emotion)\nspectogram(data, sampling_rate, emotion)\nAudio(path)","metadata":{"execution":{"iopub.status.busy":"2023-11-30T19:21:28.996215Z","iopub.execute_input":"2023-11-30T19:21:28.996725Z","iopub.status.idle":"2023-11-30T19:21:29.852959Z","shell.execute_reply.started":"2023-11-30T19:21:28.996679Z","shell.execute_reply":"2023-11-30T19:21:29.851661Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"emotion = 'neutral'\npath = np.array(df['speech'][df['label'] == emotion])[0]\ndata, sampling_rate = librosa.load(path)\nwaveplot(data, sampling_rate, emotion)\nspectogram(data, sampling_rate, emotion)\nAudio(path)","metadata":{"execution":{"iopub.status.busy":"2023-11-30T19:21:29.854458Z","iopub.execute_input":"2023-11-30T19:21:29.854830Z","iopub.status.idle":"2023-11-30T19:21:30.697730Z","shell.execute_reply.started":"2023-11-30T19:21:29.854799Z","shell.execute_reply":"2023-11-30T19:21:30.696484Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"emotion = 'sad'\npath = np.array(df['speech'][df['label'] == emotion])[0]\ndata, sampling_rate = librosa.load(path)\nwaveplot(data, sampling_rate, emotion)\nspectogram(data, sampling_rate, emotion)\nAudio(path)","metadata":{"execution":{"iopub.status.busy":"2023-11-30T19:21:30.699486Z","iopub.execute_input":"2023-11-30T19:21:30.700152Z","iopub.status.idle":"2023-11-30T19:21:31.906695Z","shell.execute_reply.started":"2023-11-30T19:21:30.700113Z","shell.execute_reply":"2023-11-30T19:21:31.901779Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"emotion = 'ps'\npath = np.array(df['speech'][df['label'] == emotion])[0]\ndata, sampling_rate = librosa.load(path)\nwaveplot(data, sampling_rate, emotion)\nspectogram(data, sampling_rate, emotion)\nAudio(path)","metadata":{"execution":{"iopub.status.busy":"2023-11-30T19:21:31.908635Z","iopub.execute_input":"2023-11-30T19:21:31.909533Z","iopub.status.idle":"2023-11-30T19:21:32.852899Z","shell.execute_reply.started":"2023-11-30T19:21:31.909482Z","shell.execute_reply":"2023-11-30T19:21:32.851579Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"emotion = 'happy'\npath = np.array(df['speech'][df['label'] == emotion])[0]\ndata, sampling_rate = librosa.load(path)\nwaveplot(data, sampling_rate, emotion)\nspectogram(data, sampling_rate, emotion)\nAudio(path)","metadata":{"execution":{"iopub.status.busy":"2023-11-30T19:21:32.854307Z","iopub.execute_input":"2023-11-30T19:21:32.855390Z","iopub.status.idle":"2023-11-30T19:21:33.643572Z","shell.execute_reply.started":"2023-11-30T19:21:32.855326Z","shell.execute_reply":"2023-11-30T19:21:33.642414Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Feature Extarction","metadata":{}},{"cell_type":"code","source":"from scipy.signal import hamming","metadata":{"execution":{"iopub.status.busy":"2023-11-30T19:21:33.645030Z","iopub.execute_input":"2023-11-30T19:21:33.645413Z","iopub.status.idle":"2023-11-30T19:21:33.649994Z","shell.execute_reply.started":"2023-11-30T19:21:33.645383Z","shell.execute_reply":"2023-11-30T19:21:33.649195Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import librosa\nimport numpy as np\n\ndef extract_mfcc_stft(file_path):\n\n    y, sr = librosa.load(file_path, duration=3)\n    \n    # STFT\n    D = librosa.stft(y)\n    S, phase = librosa.magphase(D)\n    \n    # Log scale\n    S = np.log(S + 1e-8) \n    \n    # Extract MFCCs from STFT\n    mfcc = np.mean(librosa.feature.mfcc(S=S, sr=sr, n_mfcc=40).T, axis=0)\n    \n    return mfcc","metadata":{"execution":{"iopub.status.busy":"2023-11-30T19:21:33.651289Z","iopub.execute_input":"2023-11-30T19:21:33.651812Z","iopub.status.idle":"2023-11-30T19:21:33.662691Z","shell.execute_reply.started":"2023-11-30T19:21:33.651775Z","shell.execute_reply":"2023-11-30T19:21:33.661329Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"extract_mfcc_stft(df['speech'][0])","metadata":{"execution":{"iopub.status.busy":"2023-11-30T19:21:33.664680Z","iopub.execute_input":"2023-11-30T19:21:33.665538Z","iopub.status.idle":"2023-11-30T19:21:35.068144Z","shell.execute_reply.started":"2023-11-30T19:21:33.665497Z","shell.execute_reply":"2023-11-30T19:21:35.066787Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_mfcc = df['speech'].apply(lambda x: extract_mfcc_stft(x))","metadata":{"execution":{"iopub.status.busy":"2023-11-30T19:21:35.069823Z","iopub.execute_input":"2023-11-30T19:21:35.071079Z","iopub.status.idle":"2023-11-30T19:22:27.810503Z","shell.execute_reply.started":"2023-11-30T19:21:35.071041Z","shell.execute_reply":"2023-11-30T19:22:27.809366Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_mfcc","metadata":{"execution":{"iopub.status.busy":"2023-11-30T19:22:27.811870Z","iopub.execute_input":"2023-11-30T19:22:27.812228Z","iopub.status.idle":"2023-11-30T19:22:27.825610Z","shell.execute_reply.started":"2023-11-30T19:22:27.812201Z","shell.execute_reply":"2023-11-30T19:22:27.824115Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = [x for x in X_mfcc]\nX = np.array(X)\nX.shape","metadata":{"execution":{"iopub.status.busy":"2023-11-30T19:22:27.827093Z","iopub.execute_input":"2023-11-30T19:22:27.827503Z","iopub.status.idle":"2023-11-30T19:22:27.841724Z","shell.execute_reply.started":"2023-11-30T19:22:27.827472Z","shell.execute_reply":"2023-11-30T19:22:27.840241Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## input split\n","metadata":{}},{"cell_type":"code","source":"X=np.expand_dims(X,-1)\nX.shape","metadata":{"execution":{"iopub.status.busy":"2023-11-30T19:22:27.843254Z","iopub.execute_input":"2023-11-30T19:22:27.843614Z","iopub.status.idle":"2023-11-30T19:22:27.851299Z","shell.execute_reply.started":"2023-11-30T19:22:27.843586Z","shell.execute_reply":"2023-11-30T19:22:27.849986Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import OneHotEncoder\nenc = OneHotEncoder()\ny = enc.fit_transform(df[['label']])","metadata":{"execution":{"iopub.status.busy":"2023-11-30T19:22:27.853083Z","iopub.execute_input":"2023-11-30T19:22:27.853656Z","iopub.status.idle":"2023-11-30T19:22:27.924383Z","shell.execute_reply.started":"2023-11-30T19:22:27.853570Z","shell.execute_reply":"2023-11-30T19:22:27.923182Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y = y.toarray()","metadata":{"execution":{"iopub.status.busy":"2023-11-30T19:22:27.928204Z","iopub.execute_input":"2023-11-30T19:22:27.929043Z","iopub.status.idle":"2023-11-30T19:22:27.936200Z","shell.execute_reply.started":"2023-11-30T19:22:27.929008Z","shell.execute_reply":"2023-11-30T19:22:27.935231Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y.shape","metadata":{"execution":{"iopub.status.busy":"2023-11-30T19:22:27.937583Z","iopub.execute_input":"2023-11-30T19:22:27.939010Z","iopub.status.idle":"2023-11-30T19:22:27.948812Z","shell.execute_reply.started":"2023-11-30T19:22:27.938973Z","shell.execute_reply":"2023-11-30T19:22:27.947389Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","metadata":{"execution":{"iopub.status.busy":"2023-11-30T19:22:27.950343Z","iopub.execute_input":"2023-11-30T19:22:27.951319Z","iopub.status.idle":"2023-11-30T19:22:28.081009Z","shell.execute_reply.started":"2023-11-30T19:22:27.951284Z","shell.execute_reply":"2023-11-30T19:22:28.079502Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.models import Sequential\nfrom keras.layers import Conv1D, MaxPooling1D,Dense\nfrom tensorflow.keras.layers import GlobalAveragePooling1D\nfrom keras.layers import Dropout  \nfrom keras import regularizers\n\n\n\nmodel = Sequential()\nmodel.add(Conv1D(16, 3, padding='same', activation='relu'))  \nmodel.add(Dropout(0.5))\nmodel.add(Conv1D(32, 3, kernel_regularizer=regularizers.l2(0.01)))\nmodel.add(MaxPooling1D(pool_size=2))\nmodel.add(Dropout(0.5))\nmodel.add(GlobalAveragePooling1D())\nmodel.add(Dense(7, activation='softmax'))\n\nmodel.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy']) \n\n# Train with fewer epochs\nhistory = model.fit(X_train, y_train,  \n                   epochs=100, \n                   batch_size=32, \n                   validation_data=(X_test, y_test))\n\ntrain_acc = history.history['accuracy'][-1]\nprint('Train accuracy:', train_acc)","metadata":{"execution":{"iopub.status.busy":"2023-11-30T19:22:28.087427Z","iopub.execute_input":"2023-11-30T19:22:28.088126Z","iopub.status.idle":"2023-11-30T19:23:24.252765Z","shell.execute_reply.started":"2023-11-30T19:22:28.088086Z","shell.execute_reply":"2023-11-30T19:23:24.251282Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Evaluate on training set\nimport sklearn.metrics as metrics\ntrain_loss, train_acc = model.evaluate(X_train, y_train)\n\n# Get predictions\n\ny_train_pred = model.predict(X_train).argmax(axis=1)\n\n# Calculate metrics\n\ntrain_precision = metrics.precision_score(y_train.argmax(axis=-1), y_train_pred , average='weighted')\n\ntrain_recall = metrics.recall_score(y_train.argmax(axis=-1), y_train_pred , average='weighted')\n\ntrain_f1 = metrics.f1_score(y_train.argmax(axis=-1), y_train_pred , average='weighted')\n\n# Print results\n\nprint(\"Training Accuracy: {:.4f}\".format(train_acc))\n\nprint(\"Training Precision: {:.4f}\".format(train_precision))\n\nprint(\"Training Recall: {:.4f}\".format(train_recall))\n\nprint(\"Training F1-score: {:.4f}\".format(train_f1))\n\nprint(\"Training Confusion Matrix: \")\n\nprint(metrics.confusion_matrix(y_train.argmax(axis=-1), y_train_pred))","metadata":{"execution":{"iopub.status.busy":"2023-11-30T19:23:52.485587Z","iopub.execute_input":"2023-11-30T19:23:52.486051Z","iopub.status.idle":"2023-11-30T19:23:53.097075Z","shell.execute_reply.started":"2023-11-30T19:23:52.486015Z","shell.execute_reply":"2023-11-30T19:23:53.095904Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import sklearn.metrics as metrics\n\n# Evaluate on test set\ntest_loss, test_acc = model.evaluate(X_test, y_test)\n\n# Get predictions \ny_test_pred = model.predict(X_test).argmax(axis=1)\n\n# Calculate metrics\ntest_precision = metrics.precision_score(y_test.argmax(axis=-1), y_test_pred, average='weighted')\ntest_recall = metrics.recall_score(y_test.argmax(axis=-1), y_test_pred, average='weighted') \ntest_f1 = metrics.f1_score(y_test.argmax(axis=-1), y_test_pred, average='weighted')\n\n# Print results  \nprint(\"Test Accuracy: {:.4f}\".format(test_acc))\nprint(\"Test Precision: {:.4f}\".format(test_precision))\nprint(\"Test Recall: {:.4f}\".format(test_recall))\nprint(\"Test F1-score: {:.4f}\".format(test_f1)) \n\nprint(\"Test Confusion Matrix: \")\nprint(metrics.confusion_matrix(y_test.argmax(axis=-1), y_test_pred))","metadata":{"execution":{"iopub.status.busy":"2023-11-30T19:23:56.231877Z","iopub.execute_input":"2023-11-30T19:23:56.233054Z","iopub.status.idle":"2023-11-30T19:23:56.501008Z","shell.execute_reply.started":"2023-11-30T19:23:56.233011Z","shell.execute_reply":"2023-11-30T19:23:56.498629Z"},"trusted":true},"execution_count":null,"outputs":[]}]}